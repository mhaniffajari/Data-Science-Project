{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d30c142c",
   "metadata": {},
   "source": [
    "# Simple Gen AI App Using LangChain and Google Gen AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f06dd1d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "load_dotenv()\n",
    "GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')\n",
    "LANGSMITH_API_KEY = os.getenv('LANGCHAIN_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f55c66b",
   "metadata": {},
   "source": [
    "## Data Loading from Website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c031397d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders=WebBaseLoader('https://documentation.redwood.com/extensions/Content/AzureDataFactory/AzureDataFactory-2.0.0.1.htm')\n",
    "docs = loaders.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "356a57fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://documentation.redwood.com/extensions/Content/AzureDataFactory/AzureDataFactory-2.0.0.1.htm', 'title': 'Azure Data Factory Connector 2.0.0.1', 'language': 'en-us'}, page_content='Azure Data Factory Connector 2.0.0.1\\n\\nGet instant help with our new Documentation AI Assistant. Select the Redwood logo in the bottom right to begin.\\r\\n\\t\\t\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSkip To Main Content\\n\\n\\n\\nAccount\\nSettings\\nLogout\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nplaceholder\\n\\n\\n\\n\\nAccount\\nSettings\\nLogout\\n\\n\\n\\n\\n\\n\\n\\n\\nFilter: \\n\\n\\n\\n\\n\\nAll Files\\n\\n\\n\\n\\n\\n\\nSubmit Search\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nYou are here: \\n\\n\\n\\n\\n\\nAzure Data Factory Connector 2.0.0.1\\nPrerequisites\\n\\nRunMyJobs 9.2.9 or later\\nConnection Management Extension 1.0.0.3 or later. Note that the Connection Management Extension will be installed or updated automatically if necessary when you install this Extension.\\nAzure Connections Extension (automatically installed by Catalog)\\nPrivileges Required to Use Azure Connections\\n\\nPrivileges Required to Use the Azure Data Factory Connector\\n\\n\\nSetup\\nTo install the Azure Data Factory Connector and create a Connection to Microsoft Entra (Azure AD):'),\n",
       " Document(metadata={'source': 'https://documentation.redwood.com/extensions/Content/AzureDataFactory/AzureDataFactory-2.0.0.1.htm', 'title': 'Azure Data Factory Connector 2.0.0.1', 'language': 'en-us'}, page_content='RunMyJobs 9.2.9 or later\\nConnection Management Extension 1.0.0.3 or later. Note that the Connection Management Extension will be installed or updated automatically if necessary when you install this Extension.\\nAzure Connections Extension (automatically installed by Catalog)\\nPrivileges Required to Use Azure Connections\\n\\nPrivileges Required to Use the Azure Data Factory Connector\\n\\n\\nSetup\\nTo install the Azure Data Factory Connector and create a Connection to Microsoft Entra (Azure AD): \\n\\n\\nTo install the Azure Data Factory Connector, click its tile in the Catalog, select the version you want, and then click Install <version number>.\\n\\n\\nCreate an Microsoft Entra (Azure AD) Connection.\\nNote: The Job Server for the Connector must have the ServiceForRedwood_DataFactory Job Server service.'),\n",
       " Document(metadata={'source': 'https://documentation.redwood.com/extensions/Content/AzureDataFactory/AzureDataFactory-2.0.0.1.htm', 'title': 'Azure Data Factory Connector 2.0.0.1', 'language': 'en-us'}, page_content='Privileges Required to Use the Azure Data Factory Connector\\n\\n\\nSetup\\nTo install the Azure Data Factory Connector and create a Connection to Microsoft Entra (Azure AD): \\n\\n\\nTo install the Azure Data Factory Connector, click its tile in the Catalog, select the version you want, and then click Install <version number>.\\n\\n\\nCreate an Microsoft Entra (Azure AD) Connection.\\nNote: The Job Server for the Connector must have the ServiceForRedwood_DataFactory Job Server service.\\n\\n\\nTo use the Connector, you must first create an app registration with a service principle in Azure Active Directory (see https://docs.microsoft.com/en-gb/azure/active-directory/develop/howto-create-service-principal-portal#register-an-application-with-azure-ad-and-create-a-service-principal). This client application must be assigned the Data Factory Contributor permission. Make note of the following settings from the Data Factory:\\n\\nResource Group Name\\nFactory Name\\n\\n\\n\\nContents\\n\\n\\n\\nObject Type\\nName\\n\\n\\n\\n\\nFolder'),\n",
       " Document(metadata={'source': 'https://documentation.redwood.com/extensions/Content/AzureDataFactory/AzureDataFactory-2.0.0.1.htm', 'title': 'Azure Data Factory Connector 2.0.0.1', 'language': 'en-us'}, page_content='Resource Group Name\\nFactory Name\\n\\n\\n\\nContents\\n\\n\\n\\nObject Type\\nName\\n\\n\\n\\n\\nFolder\\n\\nGLOBAL.Redwood.REDWOOD.DataFactory\\n\\n\\nJob Definition\\nREDWOOD.Redwood_DataFactory_ImportJobTemplate\\n\\n\\nJob Definition\\nREDWOOD.Redwood_DataFactory_ShowPipelines\\n\\n\\nJob Definition\\nREDWOOD.Redwood_DataFactory_RunPipeline\\n\\n\\nJob Definition\\nREDWOOD.Redwood_DataFactory_Template\\n\\n\\nLibrary\\nREDWOOD.DataFactory\\n\\n\\nJob Server Service\\nREDWOOD.ServiceForRedwood_DataFactory\\n\\n\\n\\nProcedures\\nRunning Data Factory Processes\\nThe Resource Group name is defined on the Azure Subscription.\\nFinding Data Factory Pipelines\\nTo retrieve the list of pipelines available for scheduling, go to the Redwood_DataFactory Folder, navigate to Folders > Redwood_DataFactory > DataFactory_ShowPipelines, and run it.\\n\\n\\n\\nSelect a Connection, the Resource Group Name and the Factory Name you want to list the pipelines from. You can filter the list by adding a Job Name filter.'),\n",
       " Document(metadata={'source': 'https://documentation.redwood.com/extensions/Content/AzureDataFactory/AzureDataFactory-2.0.0.1.htm', 'title': 'Azure Data Factory Connector 2.0.0.1', 'language': 'en-us'}, page_content='Procedures\\nRunning Data Factory Processes\\nThe Resource Group name is defined on the Azure Subscription.\\nFinding Data Factory Pipelines\\nTo retrieve the list of pipelines available for scheduling, go to the Redwood_DataFactory Folder, navigate to Folders > Redwood_DataFactory > DataFactory_ShowPipelines, and run it.\\n\\n\\n\\nSelect a Connection, the Resource Group Name and the Factory Name you want to list the pipelines from. You can filter the list by adding a Job Name filter.\\n\\n\\n\\nOnce the Job has finished,  choose stdout.log, and you will see the output as follows:\\n\\n\\n\\nHere you can find the value later used as pipeline name, the first element straight after the index.\\nScheduling a Data Factory Pipeline\\nIn the Redwood_DataFactory Folder, choose DataFactory_RunPipeline and run it.'),\n",
       " Document(metadata={'source': 'https://documentation.redwood.com/extensions/Content/AzureDataFactory/AzureDataFactory-2.0.0.1.htm', 'title': 'Azure Data Factory Connector 2.0.0.1', 'language': 'en-us'}, page_content='Select a Connection, the Resource Group Name and the Factory Name you want to list the pipelines from. You can filter the list by adding a Job Name filter.\\n\\n\\n\\nOnce the Job has finished,  choose stdout.log, and you will see the output as follows:\\n\\n\\n\\nHere you can find the value later used as pipeline name, the first element straight after the index.\\nScheduling a Data Factory Pipeline\\nIn the Redwood_DataFactory Folder, choose DataFactory_RunPipeline and run it.\\n\\n\\n\\nAgain, specify the Subscription ID, the Resource Group Name and the Factory Name you want to run the pipelines from, as well as the name of the pipeline to execute.\\nImporting Pipelines as Job Definitions\\nSubmit DataFactory_ImportJobTemplate to import a pipeline as a Job Definition.'),\n",
       " Document(metadata={'source': 'https://documentation.redwood.com/extensions/Content/AzureDataFactory/AzureDataFactory-2.0.0.1.htm', 'title': 'Azure Data Factory Connector 2.0.0.1', 'language': 'en-us'}, page_content='Again, specify the Subscription ID, the Resource Group Name and the Factory Name you want to run the pipelines from, as well as the name of the pipeline to execute.\\nImporting Pipelines as Job Definitions\\nSubmit DataFactory_ImportJobTemplate to import a pipeline as a Job Definition.\\n\\n\\n\\nHere the pipeline name can be used to only import a selection of pipelines. Also, the Overwrite flag can be set to specify that existing definitions can be overwritten.\\r\\nOn the Target tab it allows you to specify a target Partition, Folder, and prefix for the generated definition:\\n\\n\\n\\nTroubleshooting\\nIn the Control step of the Run Wizard, where you select the Queue, you can add additional logging to stdout.log by selecting debug in the Out Log and Error Log fields on the Advanced Options tab.\\n\\n\\n\\n\\nSpotted a typo or canâ€™t find help on a certain subject? Reach out to the Documentation team at docsupport@redwood.com.')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chunk the docs with RecursiveCharacterTextSplitter\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=500)\n",
    "docs_split = text_splitter.split_documents(docs)\n",
    "docs_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "156391a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to vector with Ollama embeddings\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "embeddings =  (OllamaEmbeddings(model=\"gemma:2b\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f0c9b37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store to vector database\n",
    "from langchain_community.vectorstores import FAISS\n",
    "vector_store = FAISS.from_documents(docs_split,embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d251d8df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Resource Group Name\\nFactory Name\\n\\n\\n\\nContents\\n\\n\\n\\nObject Type\\nName\\n\\n\\n\\n\\nFolder\\n\\nGLOBAL.Redwood.REDWOOD.DataFactory\\n\\n\\nJob Definition\\nREDWOOD.Redwood_DataFactory_ImportJobTemplate\\n\\n\\nJob Definition\\nREDWOOD.Redwood_DataFactory_ShowPipelines\\n\\n\\nJob Definition\\nREDWOOD.Redwood_DataFactory_RunPipeline\\n\\n\\nJob Definition\\nREDWOOD.Redwood_DataFactory_Template\\n\\n\\nLibrary\\nREDWOOD.DataFactory\\n\\n\\nJob Server Service\\nREDWOOD.ServiceForRedwood_DataFactory\\n\\n\\n\\nProcedures\\nRunning Data Factory Processes\\nThe Resource Group name is defined on the Azure Subscription.\\nFinding Data Factory Pipelines\\nTo retrieve the list of pipelines available for scheduling, go to the Redwood_DataFactory Folder, navigate to Folders > Redwood_DataFactory > DataFactory_ShowPipelines, and run it.\\n\\n\\n\\nSelect a Connection, the Resource Group Name and the Factory Name you want to list the pipelines from. You can filter the list by adding a Job Name filter.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similiarity search\n",
    "query = 'install the Azure Data Factory Connector'\n",
    "results = vector_store.similarity_search(query)\n",
    "results[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "269cdd78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hanif\\AppData\\Roaming\\Python\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b5754576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableLambda(format_docs)\n",
       "}), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "| ChatPromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template='\\n    Answer the question based on provided context below\\n    <context>\\n    {context}\\n    </context>\\n\\n    '), additional_kwargs={})])\n",
       "| ChatGoogleGenerativeAI(model='models/gemini-1.5-flash', google_api_key=SecretStr('**********'), client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x000001B3CB327210>, default_metadata=())\n",
       "| StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retrieval chain and document chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Answer the question based on provided context below\n",
    "    <context>\n",
    "    {context}\n",
    "    </context>\n",
    "\n",
    "    \"\"\"\n",
    ")\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "document_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7967c748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To install the Azure Data Factory Connector, locate its tile in the Catalog, choose a version, and click \"Install <version number>\".  You\\'ll then need to create a Microsoft Entra (Azure AD) connection.  The Connector\\'s Job Server requires the \"ServiceForRedwood_DataFactory\" Job Server service.  Before using the connector, register an application with a service principal in Azure Active Directory (instructions at https://docs.microsoft.com/en-gb/azure/active-directory/develop/howto-create-service-principal-portal#register-an-application-with-azure-ad-and-create-a-service-principal), assigning it the \"Data Factory Contributor\" permission. Finally, record the Resource Group Name and Factory Name from your Data Factory settings.'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "document_chain.invoke(\n",
    "    {\n",
    "        \"input\":\"Setup Azure Data Factory Connector\",\n",
    "        \"context\":[Document(page_content=\"To install the Azure Data Factory Connector, click its tile in the Catalog, select the version you want, and then click Install <version number>. Create an Microsoft Entra (Azure AD) Connection. Note: The Job Server for the Connector must have the ServiceForRedwood_DataFactory Job Server service. To use the Connector, you must first create an app registration with a service principle in Azure Active Directory (see https://docs.microsoft.com/en-gb/azure/active-directory/develop/howto-create-service-principal-portal#register-an-application-with-azure-ad-and-create-a-service-principal). This client application must be assigned the Data Factory Contributor permission. Make note of the following settings from the Data Factory: Resource Group Name Factory Name\")]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "181175bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using retriver chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "retriver = vector_store.as_retriever()\n",
    "retriver_chain = create_retrieval_chain(retriver,document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1f3fb1f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableBinding(bound=RunnableLambda(lambda x: x['input'])\n",
       "           | VectorStoreRetriever(tags=['FAISS', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001B37FC99050>, search_kwargs={}), kwargs={}, config={'run_name': 'retrieve_documents'}, config_factories=[])\n",
       "})\n",
       "| RunnableAssign(mapper={\n",
       "    answer: RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "              context: RunnableLambda(format_docs)\n",
       "            }), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "            | ChatPromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template='\\n    Answer the question based on provided context below\\n    <context>\\n    {context}\\n    </context>\\n\\n    '), additional_kwargs={})])\n",
       "            | ChatGoogleGenerativeAI(model='models/gemini-1.5-flash', google_api_key=SecretStr('**********'), client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x000001B3CB327210>, default_metadata=())\n",
       "            | StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])\n",
       "  }), kwargs={}, config={'run_name': 'retrieval_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriver_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6c05e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get the answer from LLM\n",
    "response = retriver_chain.invoke(\n",
    "    {'input': 'How to install the Azure Data Factory Connector on Redwood My Job?'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d95e2bf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the provided text, to install the Azure Data Factory Connector, you must:\\n\\n1.  Click its tile in the Catalog.\\n2.  Select the desired version (e.g., 2.0.0.1).\\n3.  Click \"Install <version number>\".\\n\\nAfter installation, you need to create a Microsoft Entra (Azure AD) Connection.  The Job Server must also have the `ServiceForRedwood_DataFactory` Job Server service.'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['answer']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
